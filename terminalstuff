rm -rf output/
rm -f centroids
CLASSPATH=/opt/hadoop-2.7.1/share/hadoop/common/*:/opt/hadoop-2.7.1/share/hadoop/yarn/lib/*:/opt/hadoop-2.7.1/share/hadoop/mapreduce/lib/*:/opt/hadoop-2.7.1/share/hadoop/mapreduce/*:./ hadoop jar KMeans.jar KMeans 4 2 kmeans_test2/points/points1.txt output kmeans_test2/centroids/centroids.txt
These are the chosen centroids from the file [2.0 2.0, -4.0 -4.0, 6.0 -6.0, -1.0 2.0]
15/11/16 18:05:53 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
15/11/16 18:05:53 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
15/11/16 18:05:53 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/11/16 18:05:53 INFO input.FileInputFormat: Total input paths to process : 1
15/11/16 18:05:53 INFO mapreduce.JobSubmitter: number of splits:1
15/11/16 18:05:53 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local934552381_0001
15/11/16 18:05:54 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/11/16 18:05:54 INFO mapreduce.Job: Running job: job_local934552381_0001
15/11/16 18:05:54 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/11/16 18:05:54 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:05:54 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/11/16 18:05:54 INFO mapred.LocalJobRunner: Waiting for map tasks
15/11/16 18:05:54 INFO mapred.LocalJobRunner: Starting task: attempt_local934552381_0001_m_000000_0
15/11/16 18:05:54 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:05:54 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:05:54 INFO mapred.MapTask: Processing split: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:05:54 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/11/16 18:05:54 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/11/16 18:05:54 INFO mapred.MapTask: soft limit at 83886080
15/11/16 18:05:54 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/11/16 18:05:54 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/11/16 18:05:54 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/11/16 18:05:54 INFO mapred.LocalJobRunner: 
15/11/16 18:05:54 INFO mapred.MapTask: Starting flush of map output
15/11/16 18:05:54 INFO mapred.MapTask: Spilling map output
15/11/16 18:05:54 INFO mapred.MapTask: bufstart = 0; bufend = 304; bufvoid = 104857600
15/11/16 18:05:54 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214324(104857296); length = 73/6553600
15/11/16 18:05:54 INFO mapred.MapTask: Finished spill 0
15/11/16 18:05:54 INFO mapred.Task: Task:attempt_local934552381_0001_m_000000_0 is done. And is in the process of committing
15/11/16 18:05:54 INFO mapred.LocalJobRunner: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:05:54 INFO mapred.Task: Task 'attempt_local934552381_0001_m_000000_0' done.
15/11/16 18:05:54 INFO mapred.LocalJobRunner: Finishing task: attempt_local934552381_0001_m_000000_0
15/11/16 18:05:54 INFO mapred.LocalJobRunner: map task executor complete.
15/11/16 18:05:54 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/11/16 18:05:54 INFO mapred.LocalJobRunner: Starting task: attempt_local934552381_0001_r_000000_0
15/11/16 18:05:54 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:05:54 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:05:54 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1bd13f0c
15/11/16 18:05:54 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/11/16 18:05:54 INFO reduce.EventFetcher: attempt_local934552381_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/11/16 18:05:54 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local934552381_0001_m_000000_0 decomp: 344 len: 348 to MEMORY
15/11/16 18:05:54 INFO reduce.InMemoryMapOutput: Read 344 bytes from map-output for attempt_local934552381_0001_m_000000_0
15/11/16 18:05:54 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 344, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->344
15/11/16 18:05:54 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/11/16 18:05:54 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/11/16 18:05:54 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:05:54 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/11/16 18:05:54 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:05:54 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:05:54 INFO reduce.MergeManagerImpl: Merged 1 segments, 344 bytes to disk to satisfy reduce memory limit
15/11/16 18:05:54 INFO reduce.MergeManagerImpl: Merging 1 files, 348 bytes from disk
15/11/16 18:05:54 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/11/16 18:05:54 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:05:54 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:05:54 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:05:54 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
15/11/16 18:05:54 INFO mapred.Task: Task:attempt_local934552381_0001_r_000000_0 is done. And is in the process of committing
15/11/16 18:05:54 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:05:54 INFO mapred.Task: Task attempt_local934552381_0001_r_000000_0 is allowed to commit now
15/11/16 18:05:54 INFO output.FileOutputCommitter: Saved output of task 'attempt_local934552381_0001_r_000000_0' to file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/output0/_temporary/0/task_local934552381_0001_r_000000
15/11/16 18:05:54 INFO mapred.LocalJobRunner: reduce > reduce
15/11/16 18:05:54 INFO mapred.Task: Task 'attempt_local934552381_0001_r_000000_0' done.
15/11/16 18:05:54 INFO mapred.LocalJobRunner: Finishing task: attempt_local934552381_0001_r_000000_0
15/11/16 18:05:54 INFO mapred.LocalJobRunner: reduce task executor complete.
15/11/16 18:05:55 INFO mapreduce.Job: Job job_local934552381_0001 running in uber mode : false
15/11/16 18:05:55 INFO mapreduce.Job:  map 100% reduce 100%
15/11/16 18:05:55 INFO mapreduce.Job: Job job_local934552381_0001 completed successfully
15/11/16 18:05:55 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=24972
		FILE: Number of bytes written=578768
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=19
		Map output records=19
		Map output bytes=304
		Map output materialized bytes=348
		Input split bytes=163
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=348
		Reduce input records=19
		Reduce output records=4
		Spilled Records=38
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=33
		Total committed heap usage (bytes)=235159552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=113
	File Output Format Counters 
		Bytes Written=90
15/11/16 18:05:55 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
15/11/16 18:05:55 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/11/16 18:05:55 INFO input.FileInputFormat: Total input paths to process : 1
15/11/16 18:05:55 INFO mapreduce.JobSubmitter: number of splits:1
15/11/16 18:05:55 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1541355366_0002
15/11/16 18:05:55 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/11/16 18:05:55 INFO mapreduce.Job: Running job: job_local1541355366_0002
15/11/16 18:05:55 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/11/16 18:05:55 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:05:55 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/11/16 18:05:55 INFO mapred.LocalJobRunner: Waiting for map tasks
15/11/16 18:05:55 INFO mapred.LocalJobRunner: Starting task: attempt_local1541355366_0002_m_000000_0
15/11/16 18:05:55 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:05:55 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:05:55 INFO mapred.MapTask: Processing split: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:05:55 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/11/16 18:05:55 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/11/16 18:05:55 INFO mapred.MapTask: soft limit at 83886080
15/11/16 18:05:55 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/11/16 18:05:55 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/11/16 18:05:55 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/11/16 18:05:55 INFO mapred.LocalJobRunner: 
15/11/16 18:05:55 INFO mapred.MapTask: Starting flush of map output
15/11/16 18:05:55 INFO mapred.MapTask: Spilling map output
15/11/16 18:05:55 INFO mapred.MapTask: bufstart = 0; bufend = 304; bufvoid = 104857600
15/11/16 18:05:55 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214324(104857296); length = 73/6553600
15/11/16 18:05:55 INFO mapred.MapTask: Finished spill 0
15/11/16 18:05:55 INFO mapred.Task: Task:attempt_local1541355366_0002_m_000000_0 is done. And is in the process of committing
15/11/16 18:05:55 INFO mapred.LocalJobRunner: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:05:55 INFO mapred.Task: Task 'attempt_local1541355366_0002_m_000000_0' done.
15/11/16 18:05:55 INFO mapred.LocalJobRunner: Finishing task: attempt_local1541355366_0002_m_000000_0
15/11/16 18:05:55 INFO mapred.LocalJobRunner: map task executor complete.
15/11/16 18:05:55 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/11/16 18:05:55 INFO mapred.LocalJobRunner: Starting task: attempt_local1541355366_0002_r_000000_0
15/11/16 18:05:55 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:05:55 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:05:55 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@58974959
15/11/16 18:05:55 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/11/16 18:05:55 INFO reduce.EventFetcher: attempt_local1541355366_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/11/16 18:05:55 INFO reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1541355366_0002_m_000000_0 decomp: 344 len: 348 to MEMORY
15/11/16 18:05:55 INFO reduce.InMemoryMapOutput: Read 344 bytes from map-output for attempt_local1541355366_0002_m_000000_0
15/11/16 18:05:55 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 344, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->344
15/11/16 18:05:55 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/11/16 18:05:55 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:05:55 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/11/16 18:05:55 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:05:55 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:05:55 INFO reduce.MergeManagerImpl: Merged 1 segments, 344 bytes to disk to satisfy reduce memory limit
15/11/16 18:05:55 INFO reduce.MergeManagerImpl: Merging 1 files, 348 bytes from disk
15/11/16 18:05:55 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/11/16 18:05:55 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:05:55 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:05:55 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:05:55 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/11/16 18:05:55 INFO mapred.Task: Task:attempt_local1541355366_0002_r_000000_0 is done. And is in the process of committing
15/11/16 18:05:55 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:05:55 INFO mapred.Task: Task attempt_local1541355366_0002_r_000000_0 is allowed to commit now
15/11/16 18:05:55 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1541355366_0002_r_000000_0' to file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/output1/_temporary/0/task_local1541355366_0002_r_000000
15/11/16 18:05:55 INFO mapred.LocalJobRunner: reduce > reduce
15/11/16 18:05:55 INFO mapred.Task: Task 'attempt_local1541355366_0002_r_000000_0' done.
15/11/16 18:05:55 INFO mapred.LocalJobRunner: Finishing task: attempt_local1541355366_0002_r_000000_0
15/11/16 18:05:55 INFO mapred.LocalJobRunner: reduce task executor complete.
15/11/16 18:05:56 INFO mapreduce.Job: Job job_local1541355366_0002 running in uber mode : false
15/11/16 18:05:56 INFO mapreduce.Job:  map 100% reduce 100%
15/11/16 18:05:56 INFO mapreduce.Job: Job job_local1541355366_0002 completed successfully
15/11/16 18:05:56 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=50672
		FILE: Number of bytes written=1160960
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=19
		Map output records=19
		Map output bytes=304
		Map output materialized bytes=348
		Input split bytes=163
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=348
		Reduce input records=19
		Reduce output records=4
		Spilled Records=38
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=29
		Total committed heap usage (bytes)=329531392
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=113
	File Output Format Counters 
		Bytes Written=96
15/11/16 18:05:56 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
15/11/16 18:05:56 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/11/16 18:05:56 INFO input.FileInputFormat: Total input paths to process : 1
15/11/16 18:05:56 INFO mapreduce.JobSubmitter: number of splits:1
15/11/16 18:05:56 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1045855246_0003
15/11/16 18:05:57 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/11/16 18:05:57 INFO mapreduce.Job: Running job: job_local1045855246_0003
15/11/16 18:05:57 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/11/16 18:05:57 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:05:57 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/11/16 18:05:57 INFO mapred.LocalJobRunner: Waiting for map tasks
15/11/16 18:05:57 INFO mapred.LocalJobRunner: Starting task: attempt_local1045855246_0003_m_000000_0
15/11/16 18:05:57 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:05:57 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:05:57 INFO mapred.MapTask: Processing split: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:05:57 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/11/16 18:05:57 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/11/16 18:05:57 INFO mapred.MapTask: soft limit at 83886080
15/11/16 18:05:57 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/11/16 18:05:57 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/11/16 18:05:57 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/11/16 18:05:57 INFO mapred.LocalJobRunner: 
15/11/16 18:05:57 INFO mapred.MapTask: Starting flush of map output
15/11/16 18:05:57 INFO mapred.MapTask: Spilling map output
15/11/16 18:05:57 INFO mapred.MapTask: bufstart = 0; bufend = 304; bufvoid = 104857600
15/11/16 18:05:57 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214324(104857296); length = 73/6553600
15/11/16 18:05:57 INFO mapred.MapTask: Finished spill 0
15/11/16 18:05:57 INFO mapred.Task: Task:attempt_local1045855246_0003_m_000000_0 is done. And is in the process of committing
15/11/16 18:05:57 INFO mapred.LocalJobRunner: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:05:57 INFO mapred.Task: Task 'attempt_local1045855246_0003_m_000000_0' done.
15/11/16 18:05:57 INFO mapred.LocalJobRunner: Finishing task: attempt_local1045855246_0003_m_000000_0
15/11/16 18:05:57 INFO mapred.LocalJobRunner: map task executor complete.
15/11/16 18:05:57 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/11/16 18:05:57 INFO mapred.LocalJobRunner: Starting task: attempt_local1045855246_0003_r_000000_0
15/11/16 18:05:57 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:05:57 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:05:57 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@79aaab5d
15/11/16 18:05:57 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/11/16 18:05:57 INFO reduce.EventFetcher: attempt_local1045855246_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/11/16 18:05:57 INFO reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1045855246_0003_m_000000_0 decomp: 344 len: 348 to MEMORY
15/11/16 18:05:57 INFO reduce.InMemoryMapOutput: Read 344 bytes from map-output for attempt_local1045855246_0003_m_000000_0
15/11/16 18:05:57 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 344, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->344
15/11/16 18:05:57 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/11/16 18:05:57 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:05:57 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/11/16 18:05:57 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:05:57 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:05:57 INFO reduce.MergeManagerImpl: Merged 1 segments, 344 bytes to disk to satisfy reduce memory limit
15/11/16 18:05:57 INFO reduce.MergeManagerImpl: Merging 1 files, 348 bytes from disk
15/11/16 18:05:57 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/11/16 18:05:57 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:05:57 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:05:57 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:05:57 INFO mapred.Task: Task:attempt_local1045855246_0003_r_000000_0 is done. And is in the process of committing
15/11/16 18:05:57 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:05:57 INFO mapred.Task: Task attempt_local1045855246_0003_r_000000_0 is allowed to commit now
15/11/16 18:05:57 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1045855246_0003_r_000000_0' to file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/output2/_temporary/0/task_local1045855246_0003_r_000000
15/11/16 18:05:57 INFO mapred.LocalJobRunner: reduce > reduce
15/11/16 18:05:57 INFO mapred.Task: Task 'attempt_local1045855246_0003_r_000000_0' done.
15/11/16 18:05:57 INFO mapred.LocalJobRunner: Finishing task: attempt_local1045855246_0003_r_000000_0
15/11/16 18:05:57 INFO mapred.LocalJobRunner: reduce task executor complete.
15/11/16 18:05:58 INFO mapreduce.Job: Job job_local1045855246_0003 running in uber mode : false
15/11/16 18:05:58 INFO mapreduce.Job:  map 100% reduce 100%
15/11/16 18:05:58 INFO mapreduce.Job: Job job_local1045855246_0003 completed successfully
15/11/16 18:05:58 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=76372
		FILE: Number of bytes written=1743158
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=19
		Map output records=19
		Map output bytes=304
		Map output materialized bytes=348
		Input split bytes=163
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=348
		Reduce input records=19
		Reduce output records=4
		Spilled Records=38
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=46
		Total committed heap usage (bytes)=512172032
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=113
	File Output Format Counters 
		Bytes Written=96
15/11/16 18:05:58 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
15/11/16 18:05:58 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/11/16 18:05:58 INFO input.FileInputFormat: Total input paths to process : 1
15/11/16 18:05:58 INFO mapreduce.JobSubmitter: number of splits:1
15/11/16 18:05:58 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local513678094_0004
15/11/16 18:05:58 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/11/16 18:05:58 INFO mapreduce.Job: Running job: job_local513678094_0004
15/11/16 18:05:58 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/11/16 18:05:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:05:58 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/11/16 18:05:58 INFO mapred.LocalJobRunner: Waiting for map tasks
15/11/16 18:05:58 INFO mapred.LocalJobRunner: Starting task: attempt_local513678094_0004_m_000000_0
15/11/16 18:05:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:05:58 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:05:58 INFO mapred.MapTask: Processing split: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:05:58 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/11/16 18:05:58 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/11/16 18:05:58 INFO mapred.MapTask: soft limit at 83886080
15/11/16 18:05:58 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/11/16 18:05:58 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/11/16 18:05:58 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/11/16 18:05:58 INFO mapred.LocalJobRunner: 
15/11/16 18:05:58 INFO mapred.MapTask: Starting flush of map output
15/11/16 18:05:58 INFO mapred.MapTask: Spilling map output
15/11/16 18:05:58 INFO mapred.MapTask: bufstart = 0; bufend = 304; bufvoid = 104857600
15/11/16 18:05:58 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214324(104857296); length = 73/6553600
15/11/16 18:05:58 INFO mapred.MapTask: Finished spill 0
15/11/16 18:05:58 INFO mapred.Task: Task:attempt_local513678094_0004_m_000000_0 is done. And is in the process of committing
15/11/16 18:05:58 INFO mapred.LocalJobRunner: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:05:58 INFO mapred.Task: Task 'attempt_local513678094_0004_m_000000_0' done.
15/11/16 18:05:58 INFO mapred.LocalJobRunner: Finishing task: attempt_local513678094_0004_m_000000_0
15/11/16 18:05:58 INFO mapred.LocalJobRunner: map task executor complete.
15/11/16 18:05:58 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/11/16 18:05:58 INFO mapred.LocalJobRunner: Starting task: attempt_local513678094_0004_r_000000_0
15/11/16 18:05:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:05:58 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:05:58 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2404b1af
15/11/16 18:05:58 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/11/16 18:05:58 INFO reduce.EventFetcher: attempt_local513678094_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/11/16 18:05:58 INFO reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local513678094_0004_m_000000_0 decomp: 344 len: 348 to MEMORY
15/11/16 18:05:58 INFO reduce.InMemoryMapOutput: Read 344 bytes from map-output for attempt_local513678094_0004_m_000000_0
15/11/16 18:05:58 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 344, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->344
15/11/16 18:05:58 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/11/16 18:05:58 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:05:58 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/11/16 18:05:58 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:05:58 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:05:58 INFO reduce.MergeManagerImpl: Merged 1 segments, 344 bytes to disk to satisfy reduce memory limit
15/11/16 18:05:58 INFO reduce.MergeManagerImpl: Merging 1 files, 348 bytes from disk
15/11/16 18:05:58 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/11/16 18:05:58 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:05:58 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:05:58 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:05:58 INFO mapred.Task: Task:attempt_local513678094_0004_r_000000_0 is done. And is in the process of committing
15/11/16 18:05:58 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:05:58 INFO mapred.Task: Task attempt_local513678094_0004_r_000000_0 is allowed to commit now
15/11/16 18:05:58 INFO output.FileOutputCommitter: Saved output of task 'attempt_local513678094_0004_r_000000_0' to file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/output3/_temporary/0/task_local513678094_0004_r_000000
15/11/16 18:05:58 INFO mapred.LocalJobRunner: reduce > reduce
15/11/16 18:05:58 INFO mapred.Task: Task 'attempt_local513678094_0004_r_000000_0' done.
15/11/16 18:05:58 INFO mapred.LocalJobRunner: Finishing task: attempt_local513678094_0004_r_000000_0
15/11/16 18:05:58 INFO mapred.LocalJobRunner: reduce task executor complete.
15/11/16 18:05:59 INFO mapreduce.Job: Job job_local513678094_0004 running in uber mode : false
15/11/16 18:05:59 INFO mapreduce.Job:  map 100% reduce 100%
15/11/16 18:05:59 INFO mapreduce.Job: Job job_local513678094_0004 completed successfully
15/11/16 18:05:59 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=102072
		FILE: Number of bytes written=2322392
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=19
		Map output records=19
		Map output bytes=304
		Map output materialized bytes=348
		Input split bytes=163
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=348
		Reduce input records=19
		Reduce output records=4
		Spilled Records=38
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=34
		Total committed heap usage (bytes)=377716736
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=113
	File Output Format Counters 
		Bytes Written=96
15/11/16 18:05:59 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
15/11/16 18:05:59 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/11/16 18:05:59 INFO input.FileInputFormat: Total input paths to process : 1
15/11/16 18:05:59 INFO mapreduce.JobSubmitter: number of splits:1
15/11/16 18:05:59 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1975459955_0005
15/11/16 18:05:59 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/11/16 18:05:59 INFO mapreduce.Job: Running job: job_local1975459955_0005
15/11/16 18:05:59 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/11/16 18:05:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:05:59 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/11/16 18:05:59 INFO mapred.LocalJobRunner: Waiting for map tasks
15/11/16 18:05:59 INFO mapred.LocalJobRunner: Starting task: attempt_local1975459955_0005_m_000000_0
15/11/16 18:05:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:05:59 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:05:59 INFO mapred.MapTask: Processing split: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:05:59 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/11/16 18:05:59 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/11/16 18:05:59 INFO mapred.MapTask: soft limit at 83886080
15/11/16 18:05:59 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/11/16 18:05:59 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/11/16 18:05:59 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/11/16 18:06:00 INFO mapred.LocalJobRunner: 
15/11/16 18:06:00 INFO mapred.MapTask: Starting flush of map output
15/11/16 18:06:00 INFO mapred.MapTask: Spilling map output
15/11/16 18:06:00 INFO mapred.MapTask: bufstart = 0; bufend = 304; bufvoid = 104857600
15/11/16 18:06:00 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214324(104857296); length = 73/6553600
15/11/16 18:06:00 INFO mapred.MapTask: Finished spill 0
15/11/16 18:06:00 INFO mapred.Task: Task:attempt_local1975459955_0005_m_000000_0 is done. And is in the process of committing
15/11/16 18:06:00 INFO mapred.LocalJobRunner: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:06:00 INFO mapred.Task: Task 'attempt_local1975459955_0005_m_000000_0' done.
15/11/16 18:06:00 INFO mapred.LocalJobRunner: Finishing task: attempt_local1975459955_0005_m_000000_0
15/11/16 18:06:00 INFO mapred.LocalJobRunner: map task executor complete.
15/11/16 18:06:00 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/11/16 18:06:00 INFO mapred.LocalJobRunner: Starting task: attempt_local1975459955_0005_r_000000_0
15/11/16 18:06:00 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:06:00 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:06:00 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4440c000
15/11/16 18:06:00 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/11/16 18:06:00 INFO reduce.EventFetcher: attempt_local1975459955_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/11/16 18:06:00 INFO reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1975459955_0005_m_000000_0 decomp: 344 len: 348 to MEMORY
15/11/16 18:06:00 INFO reduce.InMemoryMapOutput: Read 344 bytes from map-output for attempt_local1975459955_0005_m_000000_0
15/11/16 18:06:00 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 344, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->344
15/11/16 18:06:00 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/11/16 18:06:00 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:06:00 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/11/16 18:06:00 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:06:00 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:06:00 INFO reduce.MergeManagerImpl: Merged 1 segments, 344 bytes to disk to satisfy reduce memory limit
15/11/16 18:06:00 INFO reduce.MergeManagerImpl: Merging 1 files, 348 bytes from disk
15/11/16 18:06:00 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/11/16 18:06:00 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:06:00 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:06:00 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:06:00 INFO mapred.Task: Task:attempt_local1975459955_0005_r_000000_0 is done. And is in the process of committing
15/11/16 18:06:00 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:06:00 INFO mapred.Task: Task attempt_local1975459955_0005_r_000000_0 is allowed to commit now
15/11/16 18:06:00 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1975459955_0005_r_000000_0' to file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/output4/_temporary/0/task_local1975459955_0005_r_000000
15/11/16 18:06:00 INFO mapred.LocalJobRunner: reduce > reduce
15/11/16 18:06:00 INFO mapred.Task: Task 'attempt_local1975459955_0005_r_000000_0' done.
15/11/16 18:06:00 INFO mapred.LocalJobRunner: Finishing task: attempt_local1975459955_0005_r_000000_0
15/11/16 18:06:00 INFO mapred.LocalJobRunner: reduce task executor complete.
15/11/16 18:06:00 INFO mapreduce.Job: Job job_local1975459955_0005 running in uber mode : false
15/11/16 18:06:00 INFO mapreduce.Job:  map 100% reduce 100%
15/11/16 18:06:00 INFO mapreduce.Job: Job job_local1975459955_0005 completed successfully
15/11/16 18:06:00 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=127772
		FILE: Number of bytes written=2904590
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=19
		Map output records=19
		Map output bytes=304
		Map output materialized bytes=348
		Input split bytes=163
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=348
		Reduce input records=19
		Reduce output records=4
		Spilled Records=38
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=56
		Total committed heap usage (bytes)=254861312
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=113
	File Output Format Counters 
		Bytes Written=96
15/11/16 18:06:00 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
15/11/16 18:06:00 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/11/16 18:06:00 INFO input.FileInputFormat: Total input paths to process : 1
15/11/16 18:06:00 INFO mapreduce.JobSubmitter: number of splits:1
15/11/16 18:06:01 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local92973653_0006
15/11/16 18:06:01 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/11/16 18:06:01 INFO mapreduce.Job: Running job: job_local92973653_0006
15/11/16 18:06:01 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/11/16 18:06:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:06:01 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/11/16 18:06:01 INFO mapred.LocalJobRunner: Waiting for map tasks
15/11/16 18:06:01 INFO mapred.LocalJobRunner: Starting task: attempt_local92973653_0006_m_000000_0
15/11/16 18:06:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:06:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:06:01 INFO mapred.MapTask: Processing split: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:06:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/11/16 18:06:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/11/16 18:06:01 INFO mapred.MapTask: soft limit at 83886080
15/11/16 18:06:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/11/16 18:06:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/11/16 18:06:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/11/16 18:06:01 INFO mapred.LocalJobRunner: 
15/11/16 18:06:01 INFO mapred.MapTask: Starting flush of map output
15/11/16 18:06:01 INFO mapred.MapTask: Spilling map output
15/11/16 18:06:01 INFO mapred.MapTask: bufstart = 0; bufend = 304; bufvoid = 104857600
15/11/16 18:06:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214324(104857296); length = 73/6553600
15/11/16 18:06:01 INFO mapred.MapTask: Finished spill 0
15/11/16 18:06:01 INFO mapred.Task: Task:attempt_local92973653_0006_m_000000_0 is done. And is in the process of committing
15/11/16 18:06:01 INFO mapred.LocalJobRunner: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:06:01 INFO mapred.Task: Task 'attempt_local92973653_0006_m_000000_0' done.
15/11/16 18:06:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local92973653_0006_m_000000_0
15/11/16 18:06:01 INFO mapred.LocalJobRunner: map task executor complete.
15/11/16 18:06:01 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/11/16 18:06:01 INFO mapred.LocalJobRunner: Starting task: attempt_local92973653_0006_r_000000_0
15/11/16 18:06:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:06:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:06:01 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3aa54c22
15/11/16 18:06:01 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/11/16 18:06:01 INFO reduce.EventFetcher: attempt_local92973653_0006_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/11/16 18:06:01 INFO reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local92973653_0006_m_000000_0 decomp: 344 len: 348 to MEMORY
15/11/16 18:06:01 INFO reduce.InMemoryMapOutput: Read 344 bytes from map-output for attempt_local92973653_0006_m_000000_0
15/11/16 18:06:01 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 344, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->344
15/11/16 18:06:01 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/11/16 18:06:01 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:06:01 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/11/16 18:06:01 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:06:01 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:06:01 INFO reduce.MergeManagerImpl: Merged 1 segments, 344 bytes to disk to satisfy reduce memory limit
15/11/16 18:06:01 INFO reduce.MergeManagerImpl: Merging 1 files, 348 bytes from disk
15/11/16 18:06:01 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/11/16 18:06:01 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:06:01 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:06:01 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:06:01 INFO mapred.Task: Task:attempt_local92973653_0006_r_000000_0 is done. And is in the process of committing
15/11/16 18:06:01 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:06:01 INFO mapred.Task: Task attempt_local92973653_0006_r_000000_0 is allowed to commit now
15/11/16 18:06:01 INFO output.FileOutputCommitter: Saved output of task 'attempt_local92973653_0006_r_000000_0' to file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/output5/_temporary/0/task_local92973653_0006_r_000000
15/11/16 18:06:01 INFO mapred.LocalJobRunner: reduce > reduce
15/11/16 18:06:01 INFO mapred.Task: Task 'attempt_local92973653_0006_r_000000_0' done.
15/11/16 18:06:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local92973653_0006_r_000000_0
15/11/16 18:06:01 INFO mapred.LocalJobRunner: reduce task executor complete.
15/11/16 18:06:02 INFO mapreduce.Job: Job job_local92973653_0006 running in uber mode : false
15/11/16 18:06:02 INFO mapreduce.Job:  map 100% reduce 100%
15/11/16 18:06:02 INFO mapreduce.Job: Job job_local92973653_0006 completed successfully
15/11/16 18:06:02 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=153472
		FILE: Number of bytes written=3480860
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=19
		Map output records=19
		Map output bytes=304
		Map output materialized bytes=348
		Input split bytes=163
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=348
		Reduce input records=19
		Reduce output records=4
		Spilled Records=38
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=26
		Total committed heap usage (bytes)=251265024
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=113
	File Output Format Counters 
		Bytes Written=96
15/11/16 18:06:02 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
15/11/16 18:06:02 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/11/16 18:06:02 INFO input.FileInputFormat: Total input paths to process : 1
15/11/16 18:06:02 INFO mapreduce.JobSubmitter: number of splits:1
15/11/16 18:06:02 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1594817478_0007
15/11/16 18:06:02 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/11/16 18:06:02 INFO mapreduce.Job: Running job: job_local1594817478_0007
15/11/16 18:06:02 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/11/16 18:06:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:06:02 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/11/16 18:06:02 INFO mapred.LocalJobRunner: Waiting for map tasks
15/11/16 18:06:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1594817478_0007_m_000000_0
15/11/16 18:06:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:06:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:06:02 INFO mapred.MapTask: Processing split: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:06:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/11/16 18:06:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/11/16 18:06:02 INFO mapred.MapTask: soft limit at 83886080
15/11/16 18:06:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/11/16 18:06:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/11/16 18:06:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/11/16 18:06:02 INFO mapred.LocalJobRunner: 
15/11/16 18:06:02 INFO mapred.MapTask: Starting flush of map output
15/11/16 18:06:02 INFO mapred.MapTask: Spilling map output
15/11/16 18:06:02 INFO mapred.MapTask: bufstart = 0; bufend = 304; bufvoid = 104857600
15/11/16 18:06:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214324(104857296); length = 73/6553600
15/11/16 18:06:02 INFO mapred.MapTask: Finished spill 0
15/11/16 18:06:02 INFO mapred.Task: Task:attempt_local1594817478_0007_m_000000_0 is done. And is in the process of committing
15/11/16 18:06:02 INFO mapred.LocalJobRunner: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:06:02 INFO mapred.Task: Task 'attempt_local1594817478_0007_m_000000_0' done.
15/11/16 18:06:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1594817478_0007_m_000000_0
15/11/16 18:06:02 INFO mapred.LocalJobRunner: map task executor complete.
15/11/16 18:06:02 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/11/16 18:06:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1594817478_0007_r_000000_0
15/11/16 18:06:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:06:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:06:02 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7b2896bb
15/11/16 18:06:02 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/11/16 18:06:02 INFO reduce.EventFetcher: attempt_local1594817478_0007_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/11/16 18:06:02 INFO reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1594817478_0007_m_000000_0 decomp: 344 len: 348 to MEMORY
15/11/16 18:06:02 INFO reduce.InMemoryMapOutput: Read 344 bytes from map-output for attempt_local1594817478_0007_m_000000_0
15/11/16 18:06:02 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 344, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->344
15/11/16 18:06:02 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/11/16 18:06:02 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:06:02 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/11/16 18:06:02 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:06:02 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:06:02 INFO reduce.MergeManagerImpl: Merged 1 segments, 344 bytes to disk to satisfy reduce memory limit
15/11/16 18:06:02 INFO reduce.MergeManagerImpl: Merging 1 files, 348 bytes from disk
15/11/16 18:06:02 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/11/16 18:06:02 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:06:02 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:06:02 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:06:02 INFO mapred.Task: Task:attempt_local1594817478_0007_r_000000_0 is done. And is in the process of committing
15/11/16 18:06:02 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:06:02 INFO mapred.Task: Task attempt_local1594817478_0007_r_000000_0 is allowed to commit now
15/11/16 18:06:02 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1594817478_0007_r_000000_0' to file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/output6/_temporary/0/task_local1594817478_0007_r_000000
15/11/16 18:06:02 INFO mapred.LocalJobRunner: reduce > reduce
15/11/16 18:06:02 INFO mapred.Task: Task 'attempt_local1594817478_0007_r_000000_0' done.
15/11/16 18:06:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1594817478_0007_r_000000_0
15/11/16 18:06:02 INFO mapred.LocalJobRunner: reduce task executor complete.
15/11/16 18:06:03 INFO mapreduce.Job: Job job_local1594817478_0007 running in uber mode : false
15/11/16 18:06:03 INFO mapreduce.Job:  map 100% reduce 100%
15/11/16 18:06:03 INFO mapreduce.Job: Job job_local1594817478_0007 completed successfully
15/11/16 18:06:03 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=179172
		FILE: Number of bytes written=4063058
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=19
		Map output records=19
		Map output bytes=304
		Map output materialized bytes=348
		Input split bytes=163
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=348
		Reduce input records=19
		Reduce output records=4
		Spilled Records=38
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=24
		Total committed heap usage (bytes)=253599744
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=113
	File Output Format Counters 
		Bytes Written=96
15/11/16 18:06:03 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
15/11/16 18:06:03 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/11/16 18:06:03 INFO input.FileInputFormat: Total input paths to process : 1
15/11/16 18:06:03 INFO mapreduce.JobSubmitter: number of splits:1
15/11/16 18:06:03 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1179523885_0008
15/11/16 18:06:03 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/11/16 18:06:03 INFO mapreduce.Job: Running job: job_local1179523885_0008
15/11/16 18:06:03 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/11/16 18:06:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:06:03 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/11/16 18:06:03 INFO mapred.LocalJobRunner: Waiting for map tasks
15/11/16 18:06:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1179523885_0008_m_000000_0
15/11/16 18:06:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:06:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:06:03 INFO mapred.MapTask: Processing split: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:06:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/11/16 18:06:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/11/16 18:06:03 INFO mapred.MapTask: soft limit at 83886080
15/11/16 18:06:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/11/16 18:06:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/11/16 18:06:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/11/16 18:06:03 INFO mapred.LocalJobRunner: 
15/11/16 18:06:03 INFO mapred.MapTask: Starting flush of map output
15/11/16 18:06:03 INFO mapred.MapTask: Spilling map output
15/11/16 18:06:03 INFO mapred.MapTask: bufstart = 0; bufend = 304; bufvoid = 104857600
15/11/16 18:06:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214324(104857296); length = 73/6553600
15/11/16 18:06:03 INFO mapred.MapTask: Finished spill 0
15/11/16 18:06:03 INFO mapred.Task: Task:attempt_local1179523885_0008_m_000000_0 is done. And is in the process of committing
15/11/16 18:06:03 INFO mapred.LocalJobRunner: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:06:03 INFO mapred.Task: Task 'attempt_local1179523885_0008_m_000000_0' done.
15/11/16 18:06:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1179523885_0008_m_000000_0
15/11/16 18:06:03 INFO mapred.LocalJobRunner: map task executor complete.
15/11/16 18:06:03 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/11/16 18:06:03 INFO mapred.LocalJobRunner: Starting task: attempt_local1179523885_0008_r_000000_0
15/11/16 18:06:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:06:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:06:03 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@15de81ff
15/11/16 18:06:03 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/11/16 18:06:03 INFO reduce.EventFetcher: attempt_local1179523885_0008_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/11/16 18:06:03 INFO reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1179523885_0008_m_000000_0 decomp: 344 len: 348 to MEMORY
15/11/16 18:06:03 INFO reduce.InMemoryMapOutput: Read 344 bytes from map-output for attempt_local1179523885_0008_m_000000_0
15/11/16 18:06:03 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 344, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->344
15/11/16 18:06:03 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/11/16 18:06:03 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:06:03 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/11/16 18:06:03 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:06:03 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:06:03 INFO reduce.MergeManagerImpl: Merged 1 segments, 344 bytes to disk to satisfy reduce memory limit
15/11/16 18:06:03 INFO reduce.MergeManagerImpl: Merging 1 files, 348 bytes from disk
15/11/16 18:06:03 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/11/16 18:06:03 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:06:03 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:06:03 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:06:03 INFO mapred.Task: Task:attempt_local1179523885_0008_r_000000_0 is done. And is in the process of committing
15/11/16 18:06:03 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:06:03 INFO mapred.Task: Task attempt_local1179523885_0008_r_000000_0 is allowed to commit now
15/11/16 18:06:03 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1179523885_0008_r_000000_0' to file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/output7/_temporary/0/task_local1179523885_0008_r_000000
15/11/16 18:06:03 INFO mapred.LocalJobRunner: reduce > reduce
15/11/16 18:06:03 INFO mapred.Task: Task 'attempt_local1179523885_0008_r_000000_0' done.
15/11/16 18:06:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local1179523885_0008_r_000000_0
15/11/16 18:06:03 INFO mapred.LocalJobRunner: reduce task executor complete.
15/11/16 18:06:04 INFO mapreduce.Job: Job job_local1179523885_0008 running in uber mode : false
15/11/16 18:06:04 INFO mapreduce.Job:  map 100% reduce 100%
15/11/16 18:06:04 INFO mapreduce.Job: Job job_local1179523885_0008 completed successfully
15/11/16 18:06:04 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=204872
		FILE: Number of bytes written=4645256
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=19
		Map output records=19
		Map output bytes=304
		Map output materialized bytes=348
		Input split bytes=163
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=348
		Reduce input records=19
		Reduce output records=4
		Spilled Records=38
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=52
		Total committed heap usage (bytes)=245768192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=113
	File Output Format Counters 
		Bytes Written=96
15/11/16 18:06:04 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
15/11/16 18:06:04 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/11/16 18:06:04 INFO input.FileInputFormat: Total input paths to process : 1
15/11/16 18:06:04 INFO mapreduce.JobSubmitter: number of splits:1
15/11/16 18:06:04 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1313561459_0009
15/11/16 18:06:04 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/11/16 18:06:04 INFO mapreduce.Job: Running job: job_local1313561459_0009
15/11/16 18:06:04 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/11/16 18:06:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:06:04 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/11/16 18:06:04 INFO mapred.LocalJobRunner: Waiting for map tasks
15/11/16 18:06:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1313561459_0009_m_000000_0
15/11/16 18:06:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:06:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:06:04 INFO mapred.MapTask: Processing split: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:06:04 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/11/16 18:06:04 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/11/16 18:06:04 INFO mapred.MapTask: soft limit at 83886080
15/11/16 18:06:04 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/11/16 18:06:04 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/11/16 18:06:04 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/11/16 18:06:04 INFO mapred.LocalJobRunner: 
15/11/16 18:06:04 INFO mapred.MapTask: Starting flush of map output
15/11/16 18:06:04 INFO mapred.MapTask: Spilling map output
15/11/16 18:06:04 INFO mapred.MapTask: bufstart = 0; bufend = 304; bufvoid = 104857600
15/11/16 18:06:04 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214324(104857296); length = 73/6553600
15/11/16 18:06:04 INFO mapred.MapTask: Finished spill 0
15/11/16 18:06:04 INFO mapred.Task: Task:attempt_local1313561459_0009_m_000000_0 is done. And is in the process of committing
15/11/16 18:06:04 INFO mapred.LocalJobRunner: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:06:04 INFO mapred.Task: Task 'attempt_local1313561459_0009_m_000000_0' done.
15/11/16 18:06:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1313561459_0009_m_000000_0
15/11/16 18:06:04 INFO mapred.LocalJobRunner: map task executor complete.
15/11/16 18:06:04 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/11/16 18:06:04 INFO mapred.LocalJobRunner: Starting task: attempt_local1313561459_0009_r_000000_0
15/11/16 18:06:04 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:06:04 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:06:04 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@975ded
15/11/16 18:06:04 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/11/16 18:06:04 INFO reduce.EventFetcher: attempt_local1313561459_0009_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/11/16 18:06:04 INFO reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1313561459_0009_m_000000_0 decomp: 344 len: 348 to MEMORY
15/11/16 18:06:04 INFO reduce.InMemoryMapOutput: Read 344 bytes from map-output for attempt_local1313561459_0009_m_000000_0
15/11/16 18:06:04 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 344, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->344
15/11/16 18:06:04 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/11/16 18:06:04 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:06:04 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/11/16 18:06:04 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:06:04 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:06:04 INFO reduce.MergeManagerImpl: Merged 1 segments, 344 bytes to disk to satisfy reduce memory limit
15/11/16 18:06:04 INFO reduce.MergeManagerImpl: Merging 1 files, 348 bytes from disk
15/11/16 18:06:04 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/11/16 18:06:04 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:06:04 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:06:04 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:06:04 INFO mapred.Task: Task:attempt_local1313561459_0009_r_000000_0 is done. And is in the process of committing
15/11/16 18:06:04 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:06:04 INFO mapred.Task: Task attempt_local1313561459_0009_r_000000_0 is allowed to commit now
15/11/16 18:06:04 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1313561459_0009_r_000000_0' to file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/output8/_temporary/0/task_local1313561459_0009_r_000000
15/11/16 18:06:04 INFO mapred.LocalJobRunner: reduce > reduce
15/11/16 18:06:04 INFO mapred.Task: Task 'attempt_local1313561459_0009_r_000000_0' done.
15/11/16 18:06:04 INFO mapred.LocalJobRunner: Finishing task: attempt_local1313561459_0009_r_000000_0
15/11/16 18:06:04 INFO mapred.LocalJobRunner: reduce task executor complete.
15/11/16 18:06:05 INFO mapreduce.Job: Job job_local1313561459_0009 running in uber mode : false
15/11/16 18:06:05 INFO mapreduce.Job:  map 100% reduce 100%
15/11/16 18:06:05 INFO mapreduce.Job: Job job_local1313561459_0009 completed successfully
15/11/16 18:06:05 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=230572
		FILE: Number of bytes written=5227454
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=19
		Map output records=19
		Map output bytes=304
		Map output materialized bytes=348
		Input split bytes=163
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=348
		Reduce input records=19
		Reduce output records=4
		Spilled Records=38
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=29
		Total committed heap usage (bytes)=247988224
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=113
	File Output Format Counters 
		Bytes Written=96
15/11/16 18:06:05 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
15/11/16 18:06:05 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
15/11/16 18:06:05 INFO input.FileInputFormat: Total input paths to process : 1
15/11/16 18:06:05 INFO mapreduce.JobSubmitter: number of splits:1
15/11/16 18:06:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local511579654_0010
15/11/16 18:06:06 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
15/11/16 18:06:06 INFO mapreduce.Job: Running job: job_local511579654_0010
15/11/16 18:06:06 INFO mapred.LocalJobRunner: OutputCommitter set in config null
15/11/16 18:06:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:06:06 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
15/11/16 18:06:06 INFO mapred.LocalJobRunner: Waiting for map tasks
15/11/16 18:06:06 INFO mapred.LocalJobRunner: Starting task: attempt_local511579654_0010_m_000000_0
15/11/16 18:06:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:06:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:06:06 INFO mapred.MapTask: Processing split: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:06:06 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
15/11/16 18:06:06 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
15/11/16 18:06:06 INFO mapred.MapTask: soft limit at 83886080
15/11/16 18:06:06 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
15/11/16 18:06:06 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
15/11/16 18:06:06 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
15/11/16 18:06:06 INFO mapred.LocalJobRunner: 
15/11/16 18:06:06 INFO mapred.MapTask: Starting flush of map output
15/11/16 18:06:06 INFO mapred.MapTask: Spilling map output
15/11/16 18:06:06 INFO mapred.MapTask: bufstart = 0; bufend = 304; bufvoid = 104857600
15/11/16 18:06:06 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214324(104857296); length = 73/6553600
15/11/16 18:06:06 INFO mapred.MapTask: Finished spill 0
15/11/16 18:06:06 INFO mapred.Task: Task:attempt_local511579654_0010_m_000000_0 is done. And is in the process of committing
15/11/16 18:06:06 INFO mapred.LocalJobRunner: file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/kmeans_test2/points/points1.txt:0+113
15/11/16 18:06:06 INFO mapred.Task: Task 'attempt_local511579654_0010_m_000000_0' done.
15/11/16 18:06:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local511579654_0010_m_000000_0
15/11/16 18:06:06 INFO mapred.LocalJobRunner: map task executor complete.
15/11/16 18:06:06 INFO mapred.LocalJobRunner: Waiting for reduce tasks
15/11/16 18:06:06 INFO mapred.LocalJobRunner: Starting task: attempt_local511579654_0010_r_000000_0
15/11/16 18:06:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
15/11/16 18:06:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
15/11/16 18:06:06 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@46ee6763
15/11/16 18:06:06 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
15/11/16 18:06:06 INFO reduce.EventFetcher: attempt_local511579654_0010_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
15/11/16 18:06:06 INFO reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local511579654_0010_m_000000_0 decomp: 344 len: 348 to MEMORY
15/11/16 18:06:06 INFO reduce.InMemoryMapOutput: Read 344 bytes from map-output for attempt_local511579654_0010_m_000000_0
15/11/16 18:06:06 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 344, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->344
15/11/16 18:06:06 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
15/11/16 18:06:06 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:06:06 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
15/11/16 18:06:06 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:06:06 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:06:06 INFO reduce.MergeManagerImpl: Merged 1 segments, 344 bytes to disk to satisfy reduce memory limit
15/11/16 18:06:06 INFO reduce.MergeManagerImpl: Merging 1 files, 348 bytes from disk
15/11/16 18:06:06 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
15/11/16 18:06:06 INFO mapred.Merger: Merging 1 sorted segments
15/11/16 18:06:06 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 334 bytes
15/11/16 18:06:06 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:06:06 INFO mapred.Task: Task:attempt_local511579654_0010_r_000000_0 is done. And is in the process of committing
15/11/16 18:06:06 INFO mapred.LocalJobRunner: 1 / 1 copied.
15/11/16 18:06:06 INFO mapred.Task: Task attempt_local511579654_0010_r_000000_0 is allowed to commit now
15/11/16 18:06:06 INFO output.FileOutputCommitter: Saved output of task 'attempt_local511579654_0010_r_000000_0' to file:/home/physicx/Desktop/CS4320_Homework4/Skeleton_code/skeleton/output9/_temporary/0/task_local511579654_0010_r_000000
15/11/16 18:06:06 INFO mapred.LocalJobRunner: reduce > reduce
15/11/16 18:06:06 INFO mapred.Task: Task 'attempt_local511579654_0010_r_000000_0' done.
15/11/16 18:06:06 INFO mapred.LocalJobRunner: Finishing task: attempt_local511579654_0010_r_000000_0
15/11/16 18:06:06 INFO mapred.LocalJobRunner: reduce task executor complete.
15/11/16 18:06:07 INFO mapreduce.Job: Job job_local511579654_0010 running in uber mode : false
15/11/16 18:06:07 INFO mapreduce.Job:  map 100% reduce 100%
15/11/16 18:06:07 INFO mapreduce.Job: Job job_local511579654_0010 completed successfully
15/11/16 18:06:07 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=256272
		FILE: Number of bytes written=5806688
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=19
		Map output records=19
		Map output bytes=304
		Map output materialized bytes=348
		Input split bytes=163
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=348
		Reduce input records=19
		Reduce output records=4
		Spilled Records=38
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=35
		Total committed heap usage (bytes)=252174336
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=113
	File Output Format Counters 
		Bytes Written=96
============================
KMeans execution successful.
----------------------------
Number of Iterations: 10
Final centroids:[1.5 1.5, -4.5 -4.5, 6.0 -7.0, -1.0 2.3500001]
============================
